ğŸ“ Description du Projet

Ce projet implÃ©mente des mÃ©canismes de dÃ©fense avancÃ©s pour protÃ©ger l'infrastructure d'Intelligence Artificielle de l'usine Benin Moto Industry (BMI). Nous nous concentrons sur la sÃ©curitÃ© des systÃ¨mes de maintenance prÃ©dictive des presses SCHULER et des robots KUKA.

Le travail est divisÃ© en trois scÃ©narios de protection contre les menaces spÃ©cifiques Ã  l'IA.
ğŸ›¡ï¸ ScÃ©narios de SÃ©curitÃ© ImplÃ©mentÃ©s
1. [S1] DÃ©tection d'Empoisonnement (Data Poisoning)

    Objectif : EmpÃªcher l'injection de fausses donnÃ©es de capteurs qui pourraient fausser les prÃ©dictions de panne.

    Solution : Utilisation de l'algorithme Isolation Forest pour filtrer et rejeter les anomalies thermiques en temps rÃ©el.

    Scripts : plateforme_centrale.py (DÃ©fense) et generateur_capteurs.py (Attaque).

2. [S2] Protection contre l'Extraction (Model Stealing)

    Objectif : EmpÃªcher un concurrent de copier la logique du modÃ¨le via des requÃªtes API massives.

    Solution : Mise en Å“uvre d'un Rate Limiter (Limitation de dÃ©bit) qui bloque les utilisateurs dÃ©passant le quota de requÃªtes autorisÃ© (Erreur HTTP 429).

    Scripts : serveur_bmi_s2.py (API) et attaque_extraction.py (Simulation d'attaque).

3. [S5] ConfidentialitÃ© DiffÃ©rentielle (Inference Attack)

    Objectif : EmpÃªcher la fuite de donnÃ©es stratÃ©giques (cadences de production) via l'analyse des rÃ©sultats de l'IA.

    Solution : Ajout d'un bruit gaussien aux sorties du modÃ¨le via la bibliothÃ¨que Diffprivlib (IBM).

    Script : defense_inference_s5.py.

ğŸš€ Guide d'ExÃ©cution (ProcÃ©dure venv)

1. PrÃ©paration de l'environnement

Ouvrez un terminal dans le dossier du projet :
Bash

# CrÃ©er et activer l'environnement
python3 -m venv venv_bmi
source venv_bmi/bin/activate

# Installer les dÃ©pendances
pip install flask flask-limiter diffprivlib pandas scikit-learn requests

2. Lancement des simulations

    Note : L'environnement venv_bmi doit Ãªtre activÃ© (source venv_bmi/bin/activate) dans chaque nouveau terminal.

ğŸ›  ScÃ©nario 1 : DÃ©tection d'Empoisonnement

Ce test montre comment l'IA filtre les fausses donnÃ©es de tempÃ©rature injectÃ©es par un capteur compromis.

    Terminal 1 : python3 plateforme_centrale.py

    (Lance le moniteur de sÃ©curitÃ© basÃ© sur Isolation Forest)

    Terminal 2 : python3 generateur_capteurs.py

    (Simule l'envoi de donnÃ©es saines et de donnÃ©es empoisonnÃ©es)

    RÃ©sultat attendu : La console affiche "âš ï¸ ANOMALIE DÃ‰TECTÃ‰E" pour chaque tentative d'empoisonnement.

ğŸ›  ScÃ©nario 2 : Protection contre l'Extraction

Ce test valide le blocage des tentatives de vol du modÃ¨le par requÃªtes massives.

    Terminal 1 : python3 serveur_bmi_s2.py

    (Lance l'API sÃ©curisÃ©e avec Rate Limiting)

    Terminal 2 : python3 attaque_extraction.py

    (Lance le script d'attaque automatisÃ©)

    RÃ©sultat attendu : Les premiÃ¨res requÃªtes rÃ©ussissent, puis le serveur renvoie l'erreur 429 Too Many Requests.

ğŸ›  ScÃ©nario 5 : ConfidentialitÃ© DiffÃ©rentielle

Ce test dÃ©montre la protection des secrets industriels (cadences de production).

    Terminal Unique : python3 defense_inference_s5.py

    RÃ©sultat attendu : Le script affiche la valeur rÃ©elle et la valeur "bruitÃ©e" envoyÃ©e Ã  l'extÃ©rieur. On constate que la valeur bruitÃ©e change Ã  chaque fois pour tromper un espion Ã©ventuel.

ğŸ“‚ Rappel de la structure des scripts
Script	RÃ´le technique
S1 : plateforme_centrale.py	ModÃ¨le Isolation Forest qui analyse les flux entrants.
S1 : generateur_capteurs.py	Simulateur de trafic capteur avec injection de bruits malveillants.
S2 : serveur_bmi_s2.py	API Flask protÃ©gÃ©e par Flask-Limiter.
S5 : defense_inference_s5.py	ImplÃ©mentation du mÃ©canisme Gaussien de Diffprivlib.
